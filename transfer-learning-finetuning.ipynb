{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer learning 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGDQYPL7KOF-",
        "colab_type": "code",
        "outputId": "fedd5e20-1365-4215-d6ea-6f946a9da0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dropout, Flatten, Dense, Activation\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "train_data_dir = 'dataset/train1'\n",
        "validation_data_dir = 'dataset/validation1'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-j97lI7Kago",
        "colab_type": "code",
        "outputId": "2dd918bd-29d6-4240-8871-8ad6385229e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "nb_train_samples = 1000\n",
        "nb_validation_samples = 200\n",
        "epochs = 30\n",
        "batch_size = 20\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
        "\n",
        "model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
        "print('Model loaded.')\n",
        "\n",
        "top_model = Sequential()\n",
        "\n",
        "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
        "\n",
        "top_model.add(Dense(256))\n",
        "top_model.add(Activation('relu'))\n",
        "top_model.add(Dropout(0.25))\n",
        "top_model.add(Dense(1))\n",
        "top_model.add(Activation('sigmoid'))\n",
        "\n",
        "top_model.load_weights(top_model_weights_path)\n",
        "\n",
        "model = Model(input= model.input, output= top_model(model.output))\n",
        "\n",
        "for layer in model.layers[:15]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0710 16:03:16.124215 140702301972352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0710 16:03:16.173439 140702301972352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0710 16:03:16.185482 140702301972352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0710 16:03:16.223176 140702301972352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0710 16:03:17.826247 140702301972352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0710 16:03:17.827583 140702301972352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0710 16:03:21.126985 140702301972352 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model loaded.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"se...)`\n",
            "W0710 16:03:21.949894 140702301972352 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0710 16:03:21.960000 140702301972352 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJ-6D05hbjRQ",
        "colab_type": "text"
      },
      "source": [
        "The saved weights from the previous experiment ```transfer-learning-bottleneck.ipynb``` are used for finetuning the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFctMscSKwtN",
        "colab_type": "code",
        "outputId": "2b30507f-97b5-4866-c274-baccf98bc82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 2 classes.\n",
            "Found 200 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., epochs=30, validation_data=<keras_pre..., steps_per_epoch=50, validation_steps=200)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "50/50 [==============================] - 447s 9s/step - loss: 0.4058 - acc: 0.8410 - val_loss: 0.5539 - val_acc: 0.7750\n",
            "Epoch 2/30\n",
            "50/50 [==============================] - 85s 2s/step - loss: 0.4161 - acc: 0.8230 - val_loss: 0.4591 - val_acc: 0.7850\n",
            "Epoch 3/30\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.3459 - acc: 0.8460 - val_loss: 0.4518 - val_acc: 0.8100\n",
            "Epoch 4/30\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.3263 - acc: 0.8690 - val_loss: 0.4832 - val_acc: 0.8150\n",
            "Epoch 5/30\n",
            "50/50 [==============================] - 84s 2s/step - loss: 0.3310 - acc: 0.8600 - val_loss: 0.4099 - val_acc: 0.8050\n",
            "Epoch 6/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.3157 - acc: 0.8790 - val_loss: 0.4845 - val_acc: 0.8200\n",
            "Epoch 7/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2493 - acc: 0.9020 - val_loss: 0.4803 - val_acc: 0.8400\n",
            "Epoch 8/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2765 - acc: 0.8800 - val_loss: 0.4187 - val_acc: 0.8550\n",
            "Epoch 9/30\n",
            "50/50 [==============================] - 81s 2s/step - loss: 0.2410 - acc: 0.9020 - val_loss: 0.4715 - val_acc: 0.8350\n",
            "Epoch 10/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2269 - acc: 0.9130 - val_loss: 0.4450 - val_acc: 0.8550\n",
            "Epoch 11/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2040 - acc: 0.9210 - val_loss: 0.4619 - val_acc: 0.8200\n",
            "Epoch 12/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2016 - acc: 0.9200 - val_loss: 0.3456 - val_acc: 0.8550\n",
            "Epoch 13/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2093 - acc: 0.9190 - val_loss: 0.4410 - val_acc: 0.8500\n",
            "Epoch 14/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1931 - acc: 0.9280 - val_loss: 0.5484 - val_acc: 0.8350\n",
            "Epoch 15/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2023 - acc: 0.9160 - val_loss: 0.3954 - val_acc: 0.8450\n",
            "Epoch 16/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2171 - acc: 0.9010 - val_loss: 0.8827 - val_acc: 0.7000\n",
            "Epoch 17/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2183 - acc: 0.9030 - val_loss: 0.3097 - val_acc: 0.8500\n",
            "Epoch 18/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1655 - acc: 0.9400 - val_loss: 0.3472 - val_acc: 0.8500\n",
            "Epoch 19/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1585 - acc: 0.9380 - val_loss: 0.3549 - val_acc: 0.8550\n",
            "Epoch 20/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1676 - acc: 0.9380 - val_loss: 0.4959 - val_acc: 0.8450\n",
            "Epoch 21/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1764 - acc: 0.9290 - val_loss: 0.3638 - val_acc: 0.8750\n",
            "Epoch 22/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1466 - acc: 0.9410 - val_loss: 0.4988 - val_acc: 0.8400\n",
            "Epoch 23/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.2315 - acc: 0.9010 - val_loss: 0.4885 - val_acc: 0.8350\n",
            "Epoch 24/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1691 - acc: 0.9400 - val_loss: 0.2992 - val_acc: 0.8750\n",
            "Epoch 25/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1242 - acc: 0.9560 - val_loss: 0.4306 - val_acc: 0.8600\n",
            "Epoch 26/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1286 - acc: 0.9530 - val_loss: 0.3303 - val_acc: 0.8700\n",
            "Epoch 27/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1161 - acc: 0.9680 - val_loss: 0.4068 - val_acc: 0.8800\n",
            "Epoch 28/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1316 - acc: 0.9570 - val_loss: 0.3432 - val_acc: 0.8750\n",
            "Epoch 29/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1119 - acc: 0.9610 - val_loss: 0.3954 - val_acc: 0.8750\n",
            "Epoch 30/30\n",
            "50/50 [==============================] - 80s 2s/step - loss: 0.1020 - acc: 0.9620 - val_loss: 0.3549 - val_acc: 0.8800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff77046df28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-MI1bJBf3h5",
        "colab_type": "text"
      },
      "source": [
        "The model shows a lot of improvement after finetuning with validation accuracy reaching 88%. This is a sufficient demonstration of how powerful a tool transfer learning is for machine leanring in data-poor fields such as biomedical imaging etc."
      ]
    }
  ]
}